使用MQ的 10 个理由
解耦：消息队列在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口
冗余：消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险
扩展性：因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的
灵活性&峰值处理能力：能够使关键组件顶住增长的访问压力，而不是因为超出负荷的请求而完全崩溃
可恢复性：即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理
送达保证：除非客户端明确的表示已经处理完了这个消息，否则这个消息会被放回队列中去，在一段可配置的时间之后可再次被处理
顺序保证：消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理
缓冲：消息队列通过一个缓冲层来帮助任务最高效率的执行--写入队列的处理会尽可能的快速
理解数据流：消息系列通过消息被处理的频率，来方便的辅助确定那些表现不佳的处理过程或领域，这些地方的数据流都不够优化
异步通信：消息队列提供了异步处理机制，允许你把一个消息放入队列，但并不立即处理它

基础概念

BrokerKafka集群包含一个或多个服务器，这种服务器被称为broker
Topic每条发布到Kafka集群的消息都有一个类别，这个类别被称为topic。
（物理上不同topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上但用户只需指定消息的topic即可生产或消费数据而不必关心数据存于何处）
Partitionparition是物理上的概念，每个topic包含一个或多个partition，创建topic时可指定parition数量。
每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件

Producer负责发布消息到Kafka broker
Consumer消费消息。每个consumer属于一个特定的consuer group（可为每个consumer指定group name，若不指定group name则属于默认的group）。
同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息

点对点

比如：超市的结账处
超市：可以理解为一个主题（ topic ）
结账：可以理解为一个组别（ group ）
通道：可以理解为各个分区（ partition ）
通道收银员：可以理解为该组别下的各个消费者（ consumer ）
顾客：可以理解为消费对象（一条消息数据）

同一超市里一个顾客只能被结账组里的一个通道收银员消费

* Kafka的顺序就是类似这里的顺序消费，只能保证各个通道内的顺序，并不是严格意义上的先进先出

广播
比如：超市的结账处、服务台咨询处
超市：可以理解为一个主题（ topic ）
结账处：可以理解为一个组别（ group 1）
通道收银员：可以理解为group1组别下的各个消费者（ consumer ）
咨询处：可以理解为另一个组别（ group 2）
咨询员：可以理解为group2组别下的各个消费者（ consumer ）
顾客：可以理解为消费对象（一条消息数据）

同一超市里一个顾客只能被结账组里的一个通道收银员消费（结账），也可以被咨询组里的其中一个咨询员消费（咨询）

数据持久性

kafka使用文件存储消息,这就直接决定kafka在性能上严重依赖文件系统的本身特性.且无论任何OS下,对文件系统本身的优化几乎没有可能.
文件缓存/直接内存映射等是常用的手段.因为kafka是对日志文件进行append操作,因此磁盘检索的开支是较小的;
同时为了减少磁盘写入的次数,broker会将消息暂时buffer起来,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数.
log.flush.interval.messages=10000  
log文件”sync”到磁盘之前累积的消息条数,因为磁盘IO操作是一个慢操作,但又是一个”数据可靠性"的必要手段,
所以此参数的设置,需要在"数据可靠性"与"性能"之间做必要的权衡.如果此值过大,将会导致每次"fsync"的时间较长(IO阻塞),
如果此值过小,将会导致"fsync"的次数较多,这也意味着整体的client请求有一定的延迟.物理server故障,将会导致没有fsync的消息丢失
log.flush.scheduler.interval.ms =3000   检查是否需要固化到硬盘的时间间隔
log.flush.interval.ms = 1000  仅仅通过interval来控制消息的磁盘写入时机,是不足的.此参数用于控制"fsync"的时间间隔,如果消息量始终没有达到阀值,
但是离上一次磁盘同步的时间间隔达到阀值,也将触发

数据删除
log.cleanup.policy=delete启用删除策略
直接删除，删除后的消息不可恢复。可配置以下两个策略：
清理超过指定时间清理： 
log.retention.hours=16
超过指定大小后，删除旧的消息：
log.retention.bytes=1073741824
为了避免在删除时阻塞读操作，采用了copy-on-write形式的实现，删除操作进行时，读取操作的二分查找功能实际是在一个静态的快照副本上进行的。

顺序写入
因为硬盘是机械结构，每次读写都会寻址->写入，其中寻址是一个“机械动作”，它是最耗时的。所以硬盘最“讨厌”随机I/O，最喜欢顺序I/O。
为了提高读写硬盘的速度，Kafka就是使用顺序I/O。如果一个topic建立多个分区那么每个partition都是一个文文件，收到消息后Kafka会把数据插入到文件末尾。

提升网络IO的性能
需要考虑的影响性能点很多,除磁盘IO之外,还需要考虑网络IO,这直接关系到kafka的吞吐量问题.
1.sendfile
对于kafka broker端,有个sendfile系统调用可以潜在的提升网络IO的性能:将文件的数据映射到系统内存中,
    socket直接读取相应的内存区域即可,而无需进程再次
    copy和交换;
2. 批量发送与解析
     对于producer端,可以将消息buffer起来,当消息的条数达到一定阀值时,批量发送给broker;
     对于consumer端也是一样,批量fetch多条消息.消息量的大小可以通过配置文件来指定
3. 消息压缩
    其实对于producer/consumer/broker三者而言,CPU的开支应该都不大,因此启用消息压缩机制是一个良好的策略;
    压缩需要消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑.可以将任何在网络上传输的消息都经过压缩.
    kafka支持gzip/snappy等多种压缩方式.

性能效率-消费方式

consumer端向broker发送"fetch"请求,并告知其获取消息的offset;此后consumer将会获得一定条数的消息;consumer端也可以重置offset来重新消费消息.
    在JMS实现中,Topic模型基于push方式,即broker将消息推送给consumer端.不过在kafka中,采用了pull方式,
    即consumer在和broker建立连接之后,主动去pull(或者说fetch)消息;这种模式有些优点,首先consumer端可以根据自己的消费能力适时的去fetch消息并处理,
    且可以控制消息消费的进度(offset);此外,消费者可以良好的控制消息消费的数量,batch fetch.
在kafka中,partition中的消息只有一个consumer在消费,且不存在消息状态的控制,也没有复杂的消息确认机制,
可见kafka broker端是相当轻量级的.当消息被consumer接收之后,consumer可以在本地保存最后消息的offset,并间歇性的向zookeeper注册offset.
由此可见,consumer客户端也很轻量级.
Kafka会为每一个consumer group保留一些metadata信息—当前消费的消息的position，也即offset。
这个offset由consumer控制。正常情况下consumer会在消费完一条消息后线性增加这个offset。
当然，consumer也可将offset设成一个较小的值，重新消费一些消息。因为offet由consumer控制，
所以Kafka broker是无状态的，它不需要标记哪些消息被哪些consumer过，不需要通过broker去保证同一个consumer group只有一个consumer能消费某一条消息，
因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。

消息传送机制
1) at most once: 最多一次.发送一次,无论成败,将不会重发.
2) at least once: 消息至少发送一次,如果消息未能接受成功,可能会重发,直到接收成功.
3) exactly once: 消息只会发送一次.

    at most once: 消费者fetch消息,然后保存offset,然后处理消息;当client保存offset之后,
    但是在消息处理过程中出现了异常,导致部分消息未能继续处理.那么此后"未处理"的消息将不能被fetch到.
    at least once: 消费者fetch消息,然后处理消息,然后保存offset.如果消息处理成功之后,
    但是在保存offset阶段zookeeper异常导致保存操作未能执行成功,这就导致接下来再次fetch时可能获得上次已经处理过的消息,这就是"at least once"，
    原因offset没有及时的提交给zookeeper，zookeeper恢复正常还是之前offset状态.

通常情况下"at-least-once"是我们首选.(相比at most once而言,重复接收数据总比丢失数据要好).

